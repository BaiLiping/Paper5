\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@rmstyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand\BIBentrySTDinterwordspacing{\spaceskip=0pt\relax}
\providecommand\BIBentryALTinterwordstretchfactor{4}
\providecommand\BIBentryALTinterwordspacing{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand\BIBforeignlanguage[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}

\bibitem{Mnih2013PlayingAW}
V.~Mnih, K.~Kavukcuoglu, D.~Silver, A.~Graves, I.~Antonoglou, D.~Wierstra, and
  M.~A. Riedmiller, ``Playing atari with deep reinforcement learning,''
  \emph{ArXiv}, vol. abs/1312.5602, 2013.

\bibitem{Hausknecht2015DeepRQ}
M.~J. Hausknecht and P.~Stone, ``Deep recurrent q-learning for partially
  observable mdps,'' in \emph{AAAI Fall Symposia}, 2015.

\bibitem{Andrychowicz2020LearningDI}
O.~M. Andrychowicz, B.~Baker, M.~Chociej, R.~J{\'o}zefowicz, B.~McGrew, J.~W.
  Pachocki, A.~Petron, M.~Plappert, G.~Powell, A.~Ray, J.~Schneider, S.~Sidor,
  J.~Tobin, P.~Welinder, L.~Weng, and W.~Zaremba, ``Learning dexterous in-hand
  manipulation,'' \emph{The International Journal of Robotics Research},
  vol.~39, pp. 20 -- 3, 2020.

\bibitem{Kalashnikov2018QTOptSD}
D.~Kalashnikov, A.~Irpan, P.~Pastor, J.~Ibarz, A.~Herzog, E.~Jang, D.~Quillen,
  E.~Holly, M.~Kalakrishnan, V.~Vanhoucke, and S.~Levine, ``Qt-opt: Scalable
  deep reinforcement learning for vision-based robotic manipulation,''
  \emph{ArXiv}, vol. abs/1806.10293, 2018.

\bibitem{Lee2020LearningQL}
J.~Lee, J.~Hwangbo, L.~Wellhausen, V.~Koltun, and M.~Hutter, ``Learning
  quadrupedal locomotion over challenging terrain,'' \emph{Science Robotics},
  vol.~5, 2020.

\bibitem{Ho2016GenerativeAI}
J.~Ho and S.~Ermon, ``Generative adversarial imitation learning,'' in
  \emph{NIPS}, 2016.

\bibitem{Finn2016UnsupervisedLF}
C.~Finn, I.~J. Goodfellow, and S.~Levine, ``Unsupervised learning for physical
  interaction through video prediction,'' \emph{ArXiv}, vol. abs/1605.07157,
  2016.

\bibitem{Pathak2017CuriosityDrivenEB}
D.~Pathak, P.~Agrawal, A.~A. Efros, and T.~Darrell, ``Curiosity-driven
  exploration by self-supervised prediction,'' \emph{2017 IEEE Conference on
  Computer Vision and Pattern Recognition Workshops (CVPRW)}, pp. 488--489,
  2017.

\bibitem{Burda2019LargeScaleSO}
Y.~Burda, H.~Edwards, D.~Pathak, A.~Storkey, T.~Darrell, and A.~A. Efros,
  ``Large-scale study of curiosity-driven learning,'' \emph{ArXiv}, vol.
  abs/1808.04355, 2019.

\bibitem{Finn2017ModelAgnosticMF}
C.~Finn, P.~Abbeel, and S.~Levine, ``Model-agnostic meta-learning for fast
  adaptation of deep networks,'' \emph{ArXiv}, vol. abs/1703.03400, 2017.

\bibitem{Mishra2018ASN}
N.~Mishra, M.~Rohaninejad, X.~Chen, and P.~Abbeel, ``A simple neural attentive
  meta-learner,'' in \emph{ICLR}, 2018.

\bibitem{Nachum2018DataEfficientHR}
O.~Nachum, S.~Gu, H.~Lee, and S.~Levine, ``Data-efficient hierarchical
  reinforcement learning,'' \emph{ArXiv}, vol. abs/1805.08296, 2018.

\bibitem{Vezhnevets2017FeUdalNF}
A.~S. Vezhnevets, S.~Osindero, T.~Schaul, N.~Heess, M.~Jaderberg, D.~Silver,
  and K.~Kavukcuoglu, ``Feudal networks for hierarchical reinforcement
  learning,'' \emph{ArXiv}, vol. abs/1703.01161, 2017.

\bibitem{Blundell2015WeightUI}
C.~Blundell, J.~Cornebise, K.~Kavukcuoglu, and D.~Wierstra, ``Weight
  uncertainty in neural networks,'' \emph{ArXiv}, vol. abs/1505.05424, 2015.

\bibitem{Gal2017ConcreteD}
Y.~Gal, J.~Hron, and A.~Kendall, ``Concrete dropout,'' in \emph{NIPS}, 2017.

\bibitem{Dasgupta2019CausalRF}
I.~Dasgupta, J.~X. Wang, S.~Chiappa, J.~Mitrovic, P.~A. Ortega, D.~Raposo,
  E.~Hughes, P.~Battaglia, M.~Botvinick, and Z.~Kurth-Nelson, ``Causal
  reasoning from meta-reinforcement learning,'' \emph{ArXiv}, vol.
  abs/1901.08162, 2019.

\bibitem{Zhang2020DesigningOD}
J.~Zhang, ``Designing optimal dynamic treatment regimes: A causal reinforcement
  learning approach,'' in \emph{ICML 2020}, 2020.

\bibitem{Han2020ActorCriticRL}
M.~Han, L.~Zhang, J.~Wang, and W.~Pan, ``Actor-critic reinforcement learning
  for control with stability guarantee,'' \emph{IEEE Robotics and Automation
  Letters}, vol.~5, pp. 6217--6224, 2020.

\bibitem{Weinan2017APO}
E.~Weinan, ``A proposal on machine learning via dynamical systems,'' 2017.

\bibitem{Dupont2019AugmentedNO}
E.~Dupont, A.~Doucet, and Y.~Teh, ``Augmented neural odes,'' in \emph{NeurIPS},
  2019.

\bibitem{Betancourt2018OnSO}
M.~Betancourt, M.~I. Jordan, and A.~Wilson, ``On symplectic optimization,''
  \emph{arXiv: Computation}, 2018.

\bibitem{Nachum2020ReinforcementLV}
O.~Nachum and B.~Dai, ``Reinforcement learning via fenchel-rockafellar
  duality,'' \emph{ArXiv}, vol. abs/2001.01866, 2020.

\bibitem{Luo2019ADR}
F.~Luo, P.~Li, J.~Zhou, P.~Yang, B.~Chang, Z.~Sui, and X.~Sun, ``A dual
  reinforcement learning framework for unsupervised text style transfer,'' in
  \emph{IJCAI}, 2019.

\bibitem{Wu2020DataDrivenDL}
K.~Wu and D.~Xiu, ``Data-driven deep learning of partial differential equations
  in modal space,'' \emph{ArXiv}, vol. abs/1910.06948, 2020.

\bibitem{Shi2019NeuralLS}
G.~Shi, X.~Shi, M.~O'Connell, R.~Yu, K.~Azizzadenesheli, A.~Anandkumar, Y.~Yue,
  and S.-J. Chung, ``Neural lander: Stable drone landing control using learned
  dynamics,'' \emph{2019 International Conference on Robotics and Automation
  (ICRA)}, pp. 9784--9790, 2019.

\bibitem{Hewing2020LearningBasedMP}
L.~Hewing, K.~P. Wabersich, M.~Menner, and M.~N. Zeilinger, ``Learning-based
  model predictive control: Toward safe learning in control,'' 2020.

\bibitem{Mohan2020EmbeddingHP}
A.~Mohan, N.~Lubbers, D.~Livescu, and M.~Chertkov, ``Embedding hard physical
  constraints in neural network coarse-graining of 3d turbulence.''
  \emph{arXiv: Computational Physics}, 2020.

\bibitem{Lusch2018DeepLF}
B.~Lusch, J.~N. Kutz, and S.~Brunton, ``Deep learning for universal linear
  embeddings of nonlinear dynamics,'' \emph{Nature Communications}, vol.~9,
  2018.

\bibitem{Bai2019DeepEM}
S.~Bai, J.~Z. Kolter, and V.~Koltun, ``Deep equilibrium models,'' \emph{ArXiv},
  vol. abs/1909.01377, 2019.

\bibitem{BelbutePeres2020CombiningDP}
F.~de~Avila Belbute-Peres, T.~D. Economon, and J.~Z. Kolter, ``Combining
  differentiable pde solvers and graph neural networks for fluid flow
  prediction,'' \emph{ArXiv}, vol. abs/2007.04439, 2020.

\bibitem{Knox2009InteractivelySA}
W.~B. Knox and P.~Stone, ``Interactively shaping agents via human
  reinforcement: the tamer framework,'' in \emph{K-CAP '09}, 2009.

\bibitem{Knox2010CombiningMF}
------, ``Combining manual feedback with subsequent mdp reward signals for
  reinforcement learning,'' in \emph{AAMAS}, 2010.

\bibitem{Peng2018DeepMimicED}
X.~Peng, P.~Abbeel, S.~Levine, and M.~V.~D. Panne, ``Deepmimic: Example-guided
  deep reinforcement learning of physics-based character skills,'' \emph{ACM
  Trans. Graph.}, vol.~37, pp. 143:1--143:14, 2018.

\bibitem{Peng2020LearningAR}
X.~Peng, E.~Coumans, T.~Zhang, T.~Lee, J.~Tan, and S.~Levine, ``Learning agile
  robotic locomotion skills by imitating animals,'' \emph{ArXiv}, vol.
  abs/2004.00784, 2020.

\bibitem{Paine2018OneShotHI}
T.~Paine, S.~G. Colmenarejo, Z.~Wang, S.~Reed, Y.~Aytar, T.~Pfaff, M.~W.
  Hoffman, G.~Barth-Maron, S.~Cabi, D.~Budden, and N.~D. Freitas, ``One-shot
  high-fidelity imitation: Training large-scale deep nets with rl,''
  \emph{ArXiv}, vol. abs/1810.05017, 2018.

\bibitem{Xie2018LearningWT}
L.~Xie, S.~Wang, S.~Rosa, A.~Markham, and A.~Trigoni, ``Learning with training
  wheels: Speeding up training with a simple controller for deep reinforcement
  learning,'' \emph{2018 IEEE International Conference on Robotics and
  Automation (ICRA)}, pp. 6276--6283, 2018.

\bibitem{Carlucho2017IncrementalQS}
I.~Carlucho, M.~D. Paula, S.~A. Villar, and G.~G. Acosta, ``Incremental
  q-learning strategy for adaptive pid control of mobile robots,'' \emph{Expert
  Syst. Appl.}, vol.~80, pp. 183--199, 2017.

\bibitem{Pavse2020RIDMRI}
B.~S. Pavse, F.~Torabi, J.~P. Hanna, G.~Warnell, and P.~Stone, ``Ridm:
  Reinforced inverse dynamics modeling for learning from a single observed
  demonstration,'' \emph{IEEE Robotics and Automation Letters}, vol.~5, pp.
  6262--6269, 2020.

\bibitem{Powell2009WhatYS}
W.~Powell, ``What you should know about approximate dynamic programming,''
  \emph{Naval Research Logistics}, vol.~56, pp. 239--249, 2009.

\bibitem{Sutton1998IntroductionTR}
R.~Sutton and A.~Barto, ``Introduction to reinforcement learning,'' 1998.

\bibitem{Bertsekas1996NeuroDynamicP}
D.~Bertsekas and J.~Tsitsiklis, ``Neuro-dynamic programming,'' in
  \emph{Encyclopedia of Machine Learning}, 1996.

\bibitem{Nickolls2008ScalablePP}
J.~Nickolls, I.~Buck, M.~Garland, and K.~Skadron, ``Scalable parallel
  programming with cuda,'' \emph{2008 IEEE Hot Chips 20 Symposium (HCS)}, pp.
  1--2, 2008.

\bibitem{Paszke2017AutomaticDI}
A.~Paszke, S.~Gross, S.~Chintala, G.~Chanan, E.~Yang, Z.~Devito, Z.~Lin,
  A.~Desmaison, L.~Antiga, and A.~Lerer, ``Automatic differentiation in
  pytorch,'' 2017.

\bibitem{Abadi2016TensorFlowAS}
M.~Abadi, P.~Barham, J.~Chen, Z.~Chen, A.~Davis, J.~Dean, M.~Devin,
  S.~Ghemawat, G.~Irving, M.~Isard, M.~Kudlur, J.~Levenberg, R.~Monga,
  S.~Moore, D.~Murray, B.~Steiner, P.~Tucker, V.~Vasudevan, P.~Warden,
  M.~Wicke, Y.~Yu, and X.~Zhang, ``Tensorflow: A system for large-scale machine
  learning,'' \emph{ArXiv}, vol. abs/1605.08695, 2016.

\bibitem{Recht2018ATO}
B.~Recht, ``A tour of reinforcement learning: The view from continuous
  control,'' \emph{ArXiv}, vol. abs/1806.09460, 2018.

\bibitem{Osband2016DeepEV}
I.~Osband, C.~Blundell, A.~Pritzel, and B.~V. Roy, ``Deep exploration via
  bootstrapped dqn,'' \emph{ArXiv}, vol. abs/1602.04621, 2016.

\bibitem{Brockman2016OpenAIG}
G.~Brockman, V.~Cheung, L.~Pettersson, J.~Schneider, J.~Schulman, J.~Tang, and
  W.~Zaremba, ``Openai gym,'' \emph{ArXiv}, vol. abs/1606.01540, 2016.

\bibitem{tensorforce}
\BIBentryALTinterwordspacing
A.~Kuhnle, M.~Schaarschmidt, and K.~Fricke, ``Tensorforce: a tensorflow library
  for applied reinforcement learning,'' Web page, 2017. [Online]. Available:
  \url{https://github.com/tensorforce/tensorforce}
\BIBentrySTDinterwordspacing

\bibitem{Kaufmann2020DeepDA}
E.~Kaufmann, A.~Loquercio, R.~Ranftl, M.~M{\"u}ller, V.~Koltun, and
  D.~Scaramuzza, ``Deep drone acrobatics,'' \emph{ArXiv}, vol. abs/2006.05768,
  2020.

\end{thebibliography}
